Iteration:0. Training Loss:1.575967788696289 . Validation Loss:1.575967788696289
Iteration:1000. Training Loss:1.5769267082214355 . Validation Loss:1.5769267082214355
Iteration:2000. Training Loss:1.5778517723083496 . Validation Loss:1.5778517723083496
Iteration:3000. Training Loss:1.576594591140747 . Validation Loss:1.576594591140747
Iteration:4000. Training Loss:1.5832661390304565 . Validation Loss:1.5832661390304565
Iteration:5000. Training Loss:1.5745123624801636 . Validation Loss:1.5745123624801636
Iteration:6000. Training Loss:1.5674810409545898 . Validation Loss:1.5674810409545898
Iteration:7000. Training Loss:1.5711815357208252 . Validation Loss:1.5711815357208252
Iteration:8000. Training Loss:1.5874205827713013 . Validation Loss:1.5874205827713013
Iteration:9000. Training Loss:1.57584547996521 . Validation Loss:1.57584547996521
Iteration:10000. Training Loss:1.5759332180023193 . Validation Loss:1.5759332180023193
Checkpoint saved at step 10000 -> runs/run_constant.pt/checkpoint_10000.pth
Iteration:11000. Training Loss:1.5772533416748047 . Validation Loss:1.5772533416748047
Iteration:12000. Training Loss:1.5819379091262817 . Validation Loss:1.5819379091262817
Iteration:13000. Training Loss:1.5683951377868652 . Validation Loss:1.5683951377868652
Iteration:14000. Training Loss:1.562604546546936 . Validation Loss:1.562604546546936
Iteration:15000. Training Loss:1.5810365676879883 . Validation Loss:1.5810365676879883
Iteration:16000. Training Loss:1.5841532945632935 . Validation Loss:1.5841532945632935
Iteration:17000. Training Loss:1.5694377422332764 . Validation Loss:1.5694377422332764
Iteration:18000. Training Loss:1.568295955657959 . Validation Loss:1.568295955657959
Iteration:19000. Training Loss:1.5736212730407715 . Validation Loss:1.5736212730407715
Iteration:20000. Training Loss:1.5798180103302002 . Validation Loss:1.5798180103302002
Checkpoint saved at step 20000 -> runs/run_constant.pt/checkpoint_20000.pth
Iteration:21000. Training Loss:1.5706126689910889 . Validation Loss:1.5706126689910889
Iteration:22000. Training Loss:1.5916019678115845 . Validation Loss:1.5916019678115845
Iteration:23000. Training Loss:1.5729548931121826 . Validation Loss:1.5729548931121826
Iteration:24000. Training Loss:1.5789066553115845 . Validation Loss:1.5789066553115845
Iteration:25000. Training Loss:1.5850341320037842 . Validation Loss:1.5850341320037842
Iteration:26000. Training Loss:1.578728437423706 . Validation Loss:1.578728437423706
Iteration:27000. Training Loss:1.5690070390701294 . Validation Loss:1.5690070390701294
Iteration:28000. Training Loss:1.5785189867019653 . Validation Loss:1.5785189867019653
Iteration:29000. Training Loss:1.5867348909378052 . Validation Loss:1.5867348909378052
Iteration:30000. Training Loss:1.576090931892395 . Validation Loss:1.576090931892395
Checkpoint saved at step 30000 -> runs/run_constant.pt/checkpoint_30000.pth
Iteration:31000. Training Loss:1.5890884399414062 . Validation Loss:1.5890884399414062
Iteration:32000. Training Loss:1.574556589126587 . Validation Loss:1.574556589126587
Iteration:33000. Training Loss:1.5923129320144653 . Validation Loss:1.5923129320144653
Iteration:34000. Training Loss:1.580647349357605 . Validation Loss:1.580647349357605
Iteration:35000. Training Loss:1.565506100654602 . Validation Loss:1.565506100654602
Iteration:36000. Training Loss:1.5795661211013794 . Validation Loss:1.5795661211013794
Iteration:37000. Training Loss:1.5778967142105103 . Validation Loss:1.5778967142105103
Iteration:38000. Training Loss:1.5762087106704712 . Validation Loss:1.5762087106704712
Iteration:39000. Training Loss:1.576481819152832 . Validation Loss:1.576481819152832
Iteration:40000. Training Loss:1.5777008533477783 . Validation Loss:1.5777008533477783
Checkpoint saved at step 40000 -> runs/run_constant.pt/checkpoint_40000.pth
Iteration:41000. Training Loss:1.567871332168579 . Validation Loss:1.567871332168579
Iteration:42000. Training Loss:1.58380126953125 . Validation Loss:1.58380126953125
Iteration:43000. Training Loss:1.5725542306900024 . Validation Loss:1.5725542306900024
Iteration:44000. Training Loss:1.572104811668396 . Validation Loss:1.572104811668396
Iteration:45000. Training Loss:1.5760959386825562 . Validation Loss:1.5760959386825562
Iteration:46000. Training Loss:1.5714761018753052 . Validation Loss:1.5714761018753052
Iteration:47000. Training Loss:1.5770801305770874 . Validation Loss:1.5770801305770874
Iteration:48000. Training Loss:1.5729711055755615 . Validation Loss:1.5729711055755615
Iteration:49000. Training Loss:1.5818979740142822 . Validation Loss:1.5818979740142822
Iteration:50000. Training Loss:1.572013258934021 . Validation Loss:1.572013258934021
Checkpoint saved at step 50000 -> runs/run_constant.pt/checkpoint_50000.pth
Iteration:51000. Training Loss:1.5729970932006836 . Validation Loss:1.5729970932006836
Iteration:52000. Training Loss:1.5849618911743164 . Validation Loss:1.5849618911743164
Iteration:53000. Training Loss:1.5879509449005127 . Validation Loss:1.5879509449005127
Iteration:54000. Training Loss:1.5785136222839355 . Validation Loss:1.5785136222839355
Iteration:55000. Training Loss:1.5871689319610596 . Validation Loss:1.5871689319610596
Iteration:56000. Training Loss:1.56606924533844 . Validation Loss:1.56606924533844
Iteration:57000. Training Loss:1.588047981262207 . Validation Loss:1.588047981262207
Iteration:58000. Training Loss:1.5729566812515259 . Validation Loss:1.5729566812515259
Iteration:59000. Training Loss:1.5693106651306152 . Validation Loss:1.5693106651306152
Iteration:60000. Training Loss:1.5801275968551636 . Validation Loss:1.5801275968551636
Checkpoint saved at step 60000 -> runs/run_constant.pt/checkpoint_60000.pth
Iteration:61000. Training Loss:1.5726964473724365 . Validation Loss:1.5726964473724365
Iteration:62000. Training Loss:1.5736627578735352 . Validation Loss:1.5736627578735352
Iteration:63000. Training Loss:1.561703085899353 . Validation Loss:1.561703085899353
Iteration:64000. Training Loss:1.5703924894332886 . Validation Loss:1.5703924894332886
Iteration:65000. Training Loss:1.5784441232681274 . Validation Loss:1.5784441232681274
Iteration:66000. Training Loss:1.5772343873977661 . Validation Loss:1.5772343873977661
Iteration:67000. Training Loss:1.5768318176269531 . Validation Loss:1.5768318176269531
Iteration:68000. Training Loss:1.5774881839752197 . Validation Loss:1.5774881839752197
Iteration:69000. Training Loss:1.5802037715911865 . Validation Loss:1.5802037715911865
Iteration:70000. Training Loss:1.5808250904083252 . Validation Loss:1.5808250904083252
Checkpoint saved at step 70000 -> runs/run_constant.pt/checkpoint_70000.pth
Iteration:71000. Training Loss:1.5804789066314697 . Validation Loss:1.5804789066314697
Iteration:72000. Training Loss:1.587071418762207 . Validation Loss:1.587071418762207
Iteration:73000. Training Loss:1.575764775276184 . Validation Loss:1.575764775276184
Iteration:74000. Training Loss:1.5704318284988403 . Validation Loss:1.5704318284988403
Iteration:75000. Training Loss:1.5784602165222168 . Validation Loss:1.5784602165222168
Iteration:76000. Training Loss:1.5931404829025269 . Validation Loss:1.5931404829025269
Iteration:77000. Training Loss:1.5765936374664307 . Validation Loss:1.5765936374664307
Iteration:78000. Training Loss:1.583807349205017 . Validation Loss:1.583807349205017
Iteration:79000. Training Loss:1.571982741355896 . Validation Loss:1.571982741355896
Iteration:80000. Training Loss:1.5877655744552612 . Validation Loss:1.5877655744552612
Checkpoint saved at step 80000 -> runs/run_constant.pt/checkpoint_80000.pth
Iteration:81000. Training Loss:1.5733668804168701 . Validation Loss:1.5733668804168701
Iteration:82000. Training Loss:1.5827605724334717 . Validation Loss:1.5827605724334717
Iteration:83000. Training Loss:1.5709936618804932 . Validation Loss:1.5709936618804932
Iteration:84000. Training Loss:1.5777363777160645 . Validation Loss:1.5777363777160645
Iteration:85000. Training Loss:1.5780402421951294 . Validation Loss:1.5780402421951294
Iteration:86000. Training Loss:1.5788286924362183 . Validation Loss:1.5788286924362183
Iteration:87000. Training Loss:1.5890874862670898 . Validation Loss:1.5890874862670898
Iteration:88000. Training Loss:1.5798035860061646 . Validation Loss:1.5798035860061646
Iteration:89000. Training Loss:1.5766493082046509 . Validation Loss:1.5766493082046509
Iteration:90000. Training Loss:1.566123604774475 . Validation Loss:1.566123604774475
Checkpoint saved at step 90000 -> runs/run_constant.pt/checkpoint_90000.pth
Iteration:91000. Training Loss:1.5829265117645264 . Validation Loss:1.5829265117645264
Iteration:92000. Training Loss:1.5696682929992676 . Validation Loss:1.5696682929992676
Iteration:93000. Training Loss:1.5791058540344238 . Validation Loss:1.5791058540344238
Iteration:94000. Training Loss:1.5718507766723633 . Validation Loss:1.5718507766723633
Iteration:95000. Training Loss:1.5759755373001099 . Validation Loss:1.5759755373001099
Iteration:96000. Training Loss:1.572581171989441 . Validation Loss:1.572581171989441
Iteration:97000. Training Loss:1.5808899402618408 . Validation Loss:1.5808899402618408
Iteration:98000. Training Loss:1.5577807426452637 . Validation Loss:1.5577807426452637
Iteration:99000. Training Loss:1.5816080570220947 . Validation Loss:1.5816080570220947
Iteration:100000. Training Loss:1.5799871683120728 . Validation Loss:1.5799871683120728
Checkpoint saved at step 100000 -> runs/run_constant.pt/checkpoint_100000.pth
Iteration:101000. Training Loss:1.5745434761047363 . Validation Loss:1.5745434761047363
Iteration:102000. Training Loss:1.5723261833190918 . Validation Loss:1.5723261833190918
Iteration:103000. Training Loss:1.5738093852996826 . Validation Loss:1.5738093852996826
Iteration:104000. Training Loss:1.5680654048919678 . Validation Loss:1.5680654048919678
Iteration:105000. Training Loss:1.5844507217407227 . Validation Loss:1.5844507217407227
Iteration:106000. Training Loss:1.586181402206421 . Validation Loss:1.586181402206421
Iteration:107000. Training Loss:1.556458830833435 . Validation Loss:1.556458830833435
Iteration:108000. Training Loss:1.5743846893310547 . Validation Loss:1.5743846893310547
Iteration:109000. Training Loss:1.5723178386688232 . Validation Loss:1.5723178386688232
Iteration:110000. Training Loss:1.5766856670379639 . Validation Loss:1.5766856670379639
Checkpoint saved at step 110000 -> runs/run_constant.pt/checkpoint_110000.pth
Iteration:111000. Training Loss:1.5866245031356812 . Validation Loss:1.5866245031356812
Iteration:112000. Training Loss:1.5831021070480347 . Validation Loss:1.5831021070480347
Iteration:113000. Training Loss:1.5828582048416138 . Validation Loss:1.5828582048416138
Iteration:114000. Training Loss:1.5680818557739258 . Validation Loss:1.5680818557739258
Iteration:115000. Training Loss:1.572271466255188 . Validation Loss:1.572271466255188
Iteration:116000. Training Loss:1.5823932886123657 . Validation Loss:1.5823932886123657
Iteration:117000. Training Loss:1.571558952331543 . Validation Loss:1.571558952331543
Iteration:118000. Training Loss:1.575190544128418 . Validation Loss:1.575190544128418
Iteration:119000. Training Loss:1.5775182247161865 . Validation Loss:1.5775182247161865
Iteration:120000. Training Loss:1.577781319618225 . Validation Loss:1.577781319618225
Checkpoint saved at step 120000 -> runs/run_constant.pt/checkpoint_120000.pth
Iteration:121000. Training Loss:1.5763827562332153 . Validation Loss:1.5763827562332153
Iteration:122000. Training Loss:1.5706140995025635 . Validation Loss:1.5706140995025635
Iteration:123000. Training Loss:1.5824083089828491 . Validation Loss:1.5824083089828491
Iteration:124000. Training Loss:1.5694611072540283 . Validation Loss:1.5694611072540283
Iteration:125000. Training Loss:1.580557942390442 . Validation Loss:1.580557942390442
Iteration:126000. Training Loss:1.5873106718063354 . Validation Loss:1.5873106718063354
Iteration:127000. Training Loss:1.5750484466552734 . Validation Loss:1.5750484466552734
Iteration:128000. Training Loss:1.5741522312164307 . Validation Loss:1.5741522312164307
Iteration:129000. Training Loss:1.5732325315475464 . Validation Loss:1.5732325315475464
Iteration:130000. Training Loss:1.5876113176345825 . Validation Loss:1.5876113176345825
Checkpoint saved at step 130000 -> runs/run_constant.pt/checkpoint_130000.pth
Iteration:131000. Training Loss:1.5746158361434937 . Validation Loss:1.5746158361434937
Iteration:132000. Training Loss:1.5885652303695679 . Validation Loss:1.5885652303695679
Iteration:133000. Training Loss:1.5744078159332275 . Validation Loss:1.5744078159332275
Iteration:134000. Training Loss:1.5761759281158447 . Validation Loss:1.5761759281158447
Iteration:135000. Training Loss:1.571554183959961 . Validation Loss:1.571554183959961
Iteration:136000. Training Loss:1.5754989385604858 . Validation Loss:1.5754989385604858
Iteration:137000. Training Loss:1.5830143690109253 . Validation Loss:1.5830143690109253
Iteration:138000. Training Loss:1.5826302766799927 . Validation Loss:1.5826302766799927
Iteration:139000. Training Loss:1.5704975128173828 . Validation Loss:1.5704975128173828
Iteration:140000. Training Loss:1.5768299102783203 . Validation Loss:1.5768299102783203
Checkpoint saved at step 140000 -> runs/run_constant.pt/checkpoint_140000.pth
Iteration:141000. Training Loss:1.5795490741729736 . Validation Loss:1.5795490741729736
Iteration:142000. Training Loss:1.5706758499145508 . Validation Loss:1.5706758499145508
Iteration:143000. Training Loss:1.5712090730667114 . Validation Loss:1.5712090730667114
Iteration:144000. Training Loss:1.568982481956482 . Validation Loss:1.568982481956482
Iteration:145000. Training Loss:1.5795912742614746 . Validation Loss:1.5795912742614746
Iteration:146000. Training Loss:1.5819414854049683 . Validation Loss:1.5819414854049683
Iteration:147000. Training Loss:1.5785998106002808 . Validation Loss:1.5785998106002808
Iteration:148000. Training Loss:1.574337363243103 . Validation Loss:1.574337363243103
Iteration:149000. Training Loss:1.5864787101745605 . Validation Loss:1.5864787101745605
Iteration:150000. Training Loss:1.5765775442123413 . Validation Loss:1.5765775442123413
Checkpoint saved at step 150000 -> runs/run_constant.pt/checkpoint_150000.pth
Iteration:151000. Training Loss:1.5787298679351807 . Validation Loss:1.5787298679351807
Iteration:152000. Training Loss:1.5710967779159546 . Validation Loss:1.5710967779159546
Iteration:153000. Training Loss:1.5761945247650146 . Validation Loss:1.5761945247650146
Iteration:154000. Training Loss:1.5652766227722168 . Validation Loss:1.5652766227722168
Iteration:155000. Training Loss:1.575425386428833 . Validation Loss:1.575425386428833
Iteration:156000. Training Loss:1.5773041248321533 . Validation Loss:1.5773041248321533
Iteration:157000. Training Loss:1.5779727697372437 . Validation Loss:1.5779727697372437
Iteration:158000. Training Loss:1.570319652557373 . Validation Loss:1.570319652557373
Iteration:159000. Training Loss:1.5711333751678467 . Validation Loss:1.5711333751678467
Iteration:160000. Training Loss:1.5749441385269165 . Validation Loss:1.5749441385269165
Checkpoint saved at step 160000 -> runs/run_constant.pt/checkpoint_160000.pth
Iteration:161000. Training Loss:1.5783149003982544 . Validation Loss:1.5783149003982544
Iteration:162000. Training Loss:1.5804623365402222 . Validation Loss:1.5804623365402222
Iteration:163000. Training Loss:1.5805891752243042 . Validation Loss:1.5805891752243042
Iteration:164000. Training Loss:1.563628911972046 . Validation Loss:1.563628911972046
Iteration:165000. Training Loss:1.5767126083374023 . Validation Loss:1.5767126083374023
Iteration:166000. Training Loss:1.5788952112197876 . Validation Loss:1.5788952112197876
Iteration:167000. Training Loss:1.5824295282363892 . Validation Loss:1.5824295282363892
Iteration:168000. Training Loss:1.57611882686615 . Validation Loss:1.57611882686615
Iteration:169000. Training Loss:1.5697400569915771 . Validation Loss:1.5697400569915771
Iteration:170000. Training Loss:1.5637049674987793 . Validation Loss:1.5637049674987793
Checkpoint saved at step 170000 -> runs/run_constant.pt/checkpoint_170000.pth
Iteration:171000. Training Loss:1.5757923126220703 . Validation Loss:1.5757923126220703
Iteration:172000. Training Loss:1.5731117725372314 . Validation Loss:1.5731117725372314
Iteration:173000. Training Loss:1.581825613975525 . Validation Loss:1.581825613975525
Iteration:174000. Training Loss:1.5729011297225952 . Validation Loss:1.5729011297225952
Iteration:175000. Training Loss:1.5834577083587646 . Validation Loss:1.5834577083587646
Iteration:176000. Training Loss:1.5705078840255737 . Validation Loss:1.5705078840255737
Iteration:177000. Training Loss:1.5567550659179688 . Validation Loss:1.5567550659179688
Iteration:178000. Training Loss:1.5776625871658325 . Validation Loss:1.5776625871658325
Iteration:179000. Training Loss:1.577215313911438 . Validation Loss:1.577215313911438
Iteration:180000. Training Loss:1.5841212272644043 . Validation Loss:1.5841212272644043
Checkpoint saved at step 180000 -> runs/run_constant.pt/checkpoint_180000.pth
Iteration:181000. Training Loss:1.5668082237243652 . Validation Loss:1.5668082237243652
Iteration:182000. Training Loss:1.575109601020813 . Validation Loss:1.575109601020813
Iteration:183000. Training Loss:1.5772080421447754 . Validation Loss:1.5772080421447754
Iteration:184000. Training Loss:1.5717277526855469 . Validation Loss:1.5717277526855469
Iteration:185000. Training Loss:1.575804591178894 . Validation Loss:1.575804591178894
Iteration:186000. Training Loss:1.56678307056427 . Validation Loss:1.56678307056427
Iteration:187000. Training Loss:1.5618014335632324 . Validation Loss:1.5618014335632324
Iteration:188000. Training Loss:1.578867793083191 . Validation Loss:1.578867793083191
Iteration:189000. Training Loss:1.5772289037704468 . Validation Loss:1.5772289037704468
Iteration:190000. Training Loss:1.5733251571655273 . Validation Loss:1.5733251571655273
Checkpoint saved at step 190000 -> runs/run_constant.pt/checkpoint_190000.pth
Iteration:191000. Training Loss:1.5733466148376465 . Validation Loss:1.5733466148376465
Iteration:192000. Training Loss:1.5633246898651123 . Validation Loss:1.5633246898651123
Iteration:193000. Training Loss:1.5843244791030884 . Validation Loss:1.5843244791030884
Iteration:194000. Training Loss:1.5841435194015503 . Validation Loss:1.5841435194015503
Iteration:195000. Training Loss:1.5654078722000122 . Validation Loss:1.5654078722000122
Iteration:196000. Training Loss:1.5795906782150269 . Validation Loss:1.5795906782150269
Iteration:197000. Training Loss:1.572698712348938 . Validation Loss:1.572698712348938
Iteration:198000. Training Loss:1.5752722024917603 . Validation Loss:1.5752722024917603
Iteration:199000. Training Loss:1.5777029991149902 . Validation Loss:1.5777029991149902
Iteration:200000. Training Loss:1.5750532150268555 . Validation Loss:1.5750532150268555
Checkpoint saved at step 200000 -> runs/run_constant.pt/checkpoint_200000.pth
Iteration:201000. Training Loss:1.5869982242584229 . Validation Loss:1.5869982242584229
Iteration:202000. Training Loss:1.5889688730239868 . Validation Loss:1.5889688730239868
Iteration:203000. Training Loss:1.5746936798095703 . Validation Loss:1.5746936798095703
Iteration:204000. Training Loss:1.5664081573486328 . Validation Loss:1.5664081573486328
Iteration:205000. Training Loss:1.5906460285186768 . Validation Loss:1.5906460285186768
Iteration:206000. Training Loss:1.5863810777664185 . Validation Loss:1.5863810777664185
Iteration:207000. Training Loss:1.5724639892578125 . Validation Loss:1.5724639892578125
Iteration:208000. Training Loss:1.5820049047470093 . Validation Loss:1.5820049047470093
Iteration:209000. Training Loss:1.5809048414230347 . Validation Loss:1.5809048414230347
Iteration:210000. Training Loss:1.5818414688110352 . Validation Loss:1.5818414688110352
Checkpoint saved at step 210000 -> runs/run_constant.pt/checkpoint_210000.pth
Iteration:211000. Training Loss:1.5703200101852417 . Validation Loss:1.5703200101852417
Iteration:212000. Training Loss:1.5721991062164307 . Validation Loss:1.5721991062164307
Iteration:213000. Training Loss:1.5574781894683838 . Validation Loss:1.5574781894683838
Iteration:214000. Training Loss:1.5782719850540161 . Validation Loss:1.5782719850540161
Iteration:215000. Training Loss:1.576027750968933 . Validation Loss:1.576027750968933
Iteration:216000. Training Loss:1.5816410779953003 . Validation Loss:1.5816410779953003
Iteration:217000. Training Loss:1.5843490362167358 . Validation Loss:1.5843490362167358
Iteration:218000. Training Loss:1.577785849571228 . Validation Loss:1.577785849571228
Iteration:219000. Training Loss:1.587822437286377 . Validation Loss:1.587822437286377
Iteration:220000. Training Loss:1.577116847038269 . Validation Loss:1.577116847038269
Checkpoint saved at step 220000 -> runs/run_constant.pt/checkpoint_220000.pth
Iteration:221000. Training Loss:1.554023027420044 . Validation Loss:1.554023027420044
Iteration:222000. Training Loss:1.557664155960083 . Validation Loss:1.557664155960083
Iteration:223000. Training Loss:1.576512098312378 . Validation Loss:1.576512098312378
Iteration:224000. Training Loss:1.5764504671096802 . Validation Loss:1.5764504671096802
Iteration:225000. Training Loss:1.5744731426239014 . Validation Loss:1.5744731426239014
Iteration:226000. Training Loss:1.5728967189788818 . Validation Loss:1.5728967189788818
Iteration:227000. Training Loss:1.5864455699920654 . Validation Loss:1.5864455699920654
Iteration:228000. Training Loss:1.5701438188552856 . Validation Loss:1.5701438188552856
